{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a short experiment implementing DeepMind's A3C algorithm to solve the traffic lights problem. The implementation is by no means meant to be original, instead draws for different versions available online.\n",
    "\n",
    "The concrete statement of the traffic lights problems is as follows:\n",
    "\n",
    "Suppose you are a path which contain a number $lights$ of traffic lights, each of which displays a random amount of time $time\\_left$, uniformily distributed on the interval $[0, time]$ to be waited to before you may cross. Suppose additionally that the time displayed in each of the lights is independent form the others. In your pocession you have a device that allows you to skip a number $uses$ of lights.\n",
    "Given that you use the optimal strategy, what is the expected amount of waiting time on the whole path?\n",
    "\n",
    "Using the independence of the traffic lights it is quite easy to derive a recursive formula for the optimal strategy. The goal of the present experiment is to answer the question: \"can a neural network learn the optimal strategy from experience?\"\n",
    "\n",
    "At it's present state, our agent manages to attain around 80%+ of the optimal performance, however, the training is not stable, some lucky runs might see performances above 96% and some unlucky runs can see the agent performing no better than random choice.\n",
    "Current work is being done to implement a recurent version of this algorithm in hopes to improve stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import numpy as np\n",
    "# set the random seed\n",
    "#np.random.seed(42)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# global variables for threading\n",
    "episode = 0\n",
    "scores = []\n",
    "\n",
    "# settings regarting the actor-critic network\n",
    "EPISODES = 100000\n",
    "ENTROPY_FACTOR = 0.025\n",
    "LEARNING_RATE = 0.000025\n",
    "CRITIC_FACTOR = 1\n",
    "DISCOUNT = 0.9\n",
    "HIDDEN_1_SIZE = 64\n",
    "HIDDEN_2_SIZE = 128\n",
    "THREADS = 8\n",
    "ALPHA = 0.0001\n",
    "\n",
    "# settings for the traffic lights enviroment to be used for training\n",
    "MAX_LIGHTS = 25  # max number of lights if this is allowed to be random\n",
    "LIGHTS= 10  # number of lights, set to None for random\n",
    "USES = None  # number of times on can skip a light, set to None for random\n",
    "TIME = 100  # maximum waiting time at each light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimated_time_recursion(lights, uses, time=TIME):\n",
    "    \"\"\"This is the recursive solution\"\"\"\n",
    "    if lights == 0:\n",
    "        return 0\n",
    "    elif uses == 0:\n",
    "        return lights*time/2\n",
    "    elif lights <= uses:\n",
    "        return 0\n",
    "    else:\n",
    "        a = estimated_time_recursion(lights - 1, uses - 1, time)\n",
    "        return a - (1/(2*time))*(a - estimated_time_recursion(lights - 1, uses, time))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficLightsProblem:\n",
    "    \"\"\"Enviroment for the traffic lights problem \n",
    "    following the template from OpenAI Gym \n",
    "    \"\"\"\n",
    "    def __init__(self, lights=LIGHTS, uses=USES):\n",
    "        if lights is None:\n",
    "            self.lights = np.random.randint(low=2, high=MAX_LIGHTS + 1)\n",
    "        else:\n",
    "            self.lights = lights\n",
    "\n",
    "        if uses is None:\n",
    "            self.uses = np.random.randint(low=1, high=self.lights)\n",
    "        else:\n",
    "            self.uses = uses\n",
    "\n",
    "        self.time_left = np.random.randint(low=0, high=TIME + 1)\n",
    "        \n",
    "        self.total_time = 0\n",
    "\n",
    "    def reset(self, lights=LIGHTS, uses=USES):\n",
    "        if lights is None:\n",
    "            self.lights = np.random.randint(low=2, high=MAX_LIGHTS + 1)\n",
    "        else:\n",
    "            self.lights = lights\n",
    "\n",
    "        if uses is None:\n",
    "            self.uses = np.random.randint(low=1, high=self.lights)\n",
    "        else:\n",
    "            self.uses = uses\n",
    "        \n",
    "        self.total_time = 0\n",
    "        self.time_left = np.random.randint(low=0, high=TIME + 1)\n",
    "        return np.array([self.lights, self.uses, self.time_left])\n",
    "\n",
    "    def step(self, action=0):\n",
    "        self.lights -= 1\n",
    "        reward = 0\n",
    "        \n",
    "        if action == 1 and self.uses > 0:\n",
    "            self.uses -= 1\n",
    "            reward = self.time_left  #if the agent uses the device, we reward it with the time it saved\n",
    "        else:\n",
    "            self.total_time += self.time_left\n",
    "        \n",
    "        if self.uses <= 0:\n",
    "            self.total_time += sum(np.random.randint(low=0, high=TIME + 1) for i in range(self.lights))\n",
    "            self.lights = 0\n",
    "        elif self.uses >= self.lights:\n",
    "            self.lights = 0\n",
    "        \n",
    "        self.time_left = np.random.randint(low=0, high=TIME + 1) if self.lights > 0 else 0\n",
    "        \n",
    "        if self.lights == 0:\n",
    "            reward += -self.total_time  # by the end of the game, we penalize the agent with the total time\n",
    "\n",
    "        return [np.array([self.lights, self.uses, self.time_left]), reward, self.lights == 0, {}]\n",
    "\n",
    "    def state(self):\n",
    "        return np.array([self.lights, self.uses, self.time_left])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class A3CAgent:\n",
    "    \"\"\"A3C agent addapted for our enviroment \"\"\"\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # Hyper parameters as defined in the settings\n",
    "        self.actor_lr = LEARNING_RATE\n",
    "        self.critic_lr = CRITIC_FACTOR*LEARNING_RATE\n",
    "        self.discount_factor = DISCOUNT\n",
    "        self.hidden1, self.hidden2 = HIDDEN_1_SIZE, HIDDEN_2_SIZE\n",
    "        self.entropy_factor = ENTROPY_FACTOR\n",
    "        self.threads = THREADS\n",
    "\n",
    "        # create model for actor and critic network\n",
    "        self.actor, self.critic = self.build_model()\n",
    "\n",
    "        # method for training actor and critic network\n",
    "        self.optimizer = [self.actor_optimizer(), self.critic_optimizer()]\n",
    "\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        K.set_session(self.sess)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # actor -> state is input and probability of each action is output of network\n",
    "    # critic -> state is input and value of state is output of network\n",
    "    # actor and critic network share first hidden layer\n",
    "    def build_model(self):\n",
    "        state = Input(batch_shape=(None,  self.state_size))\n",
    "        shared_1 = Dense(self.hidden1, input_dim=self.state_size, activation='relu', kernel_initializer='glorot_uniform')(state)\n",
    "        shared_2 = Dense(self.hidden1, input_dim=self.state_size, activation='relu', kernel_initializer='glorot_uniform')(shared_1)\n",
    "        shared_f = Dense(self.hidden2, input_dim=self.state_size, activation='relu', kernel_initializer='glorot_uniform')(shared_2)\n",
    "\n",
    "        actor_hidden = Dense(self.hidden2, activation='relu', kernel_initializer='glorot_uniform')(shared_f)\n",
    "        action_prob = Dense(self.action_size, activation='softmax', kernel_initializer='glorot_uniform')(actor_hidden)\n",
    "\n",
    "        value_hidden = Dense(self.hidden2, activation='relu', kernel_initializer='he_uniform')(shared_f)\n",
    "        state_value = Dense(1, activation='linear', kernel_initializer='he_uniform')(value_hidden)\n",
    "\n",
    "        actor = Model(inputs=state, outputs=action_prob)\n",
    "        critic = Model(inputs=state, outputs=state_value)\n",
    "\n",
    "        actor._make_predict_function()\n",
    "        critic._make_predict_function()\n",
    "\n",
    "        actor.summary()\n",
    "        critic.summary()\n",
    "\n",
    "        return actor, critic\n",
    "\n",
    "    # loss function for Policy Gradient\n",
    "    # added entropy to encourage exploration\n",
    "    def actor_optimizer(self):\n",
    "        action = K.placeholder(shape=(None, self.action_size))\n",
    "        advantages = K.placeholder(shape=(None, ))\n",
    "\n",
    "        policy = self.actor.output\n",
    "\n",
    "        good_prob = K.sum(action * policy, axis=1)\n",
    "        eligibility = K.log(good_prob + 1e-10) * K.stop_gradient(advantages)\n",
    "        loss = -K.sum(eligibility)\n",
    "\n",
    "        entropy = K.sum(policy * K.log(policy + 1e-10), axis=1)\n",
    "\n",
    "        actor_loss = loss + self.entropy_factor*entropy\n",
    "\n",
    "        optimizer = RMSprop(lr=self.actor_lr)\n",
    "        updates = optimizer.get_updates(self.actor.trainable_weights, [], actor_loss)\n",
    "        train = K.function([self.actor.input, action, advantages], [], updates=updates)\n",
    "        return train\n",
    "\n",
    "    # loss function for Value approximation\n",
    "    def critic_optimizer(self):\n",
    "        discounted_reward = K.placeholder(shape=(None, ))\n",
    "\n",
    "        value = self.critic.output\n",
    "\n",
    "        loss = K.mean(K.square(discounted_reward - value))\n",
    "\n",
    "        optimizer = RMSprop(lr=self.critic_lr)\n",
    "        updates = optimizer.get_updates(self.critic.trainable_weights, [], loss)\n",
    "        train = K.function([self.critic.input, discounted_reward], [], updates=updates)\n",
    "        return train\n",
    "\n",
    "    # generate the separate agents for training\n",
    "    def train(self):\n",
    "        agents = [Agent(i, self.actor, self.critic, self.optimizer, self.discount_factor,\n",
    "                        self.action_size, self.state_size) for i in range(self.threads)]\n",
    "\n",
    "        for agent in agents:\n",
    "            agent.start()\n",
    "            \n",
    "        for agent in agents:\n",
    "            agent.join()\n",
    "            \n",
    "        scores_pd = pd.DataFrame(scores)    \n",
    "        rolling = scores_pd.rolling(window=50,center=False).mean()\n",
    "        ax_scores = scores_pd.plot(alpha=0.3, legend=False)\n",
    "        rolling.plot(ax=ax_scores, legend=False)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Agent(threading.Thread):\n",
    "    \"\"\"agent class for threading \"\"\"\n",
    "    def __init__(self, index, actor, critic, optimizer, discount_factor, action_size, state_size):\n",
    "        threading.Thread.__init__(self)\n",
    "\n",
    "        self.states = []\n",
    "        self.rewards = []\n",
    "        self.actions = []\n",
    "\n",
    "        self.index = index\n",
    "        self.actor = actor\n",
    "        self.critic = critic\n",
    "        self.optimizer = optimizer\n",
    "        self.discount_factor = discount_factor\n",
    "        self.action_size = action_size\n",
    "        self.state_size = state_size\n",
    "\n",
    "    # thread interacting with environment\n",
    "    def run(self):\n",
    "        global episode\n",
    "        env = TrafficLightsProblem()\n",
    "        while episode < EPISODES:\n",
    "            state = env.reset()\n",
    "            score = 0\n",
    "            normalizator = TIME*(env.lights - env.uses)/2\n",
    "            while True:\n",
    "                action = self.get_action(state)\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "                score += reward/(normalizator)\n",
    "\n",
    "                self.memory(state, action, reward/normalizator)\n",
    "\n",
    "                state = next_state\n",
    "\n",
    "                if done:\n",
    "                    episode += 1\n",
    "                    #print(\"episode: \", episode, \"/ score : \", score)\n",
    "                    scores.append(score)\n",
    "                    \n",
    "                    self.train_episode(False)\n",
    "                    break\n",
    "\n",
    "    def discount_rewards(self, rewards, done=True):\n",
    "        discounted_rewards = np.zeros_like(rewards)\n",
    "        running_add = 0\n",
    "        if not done:\n",
    "            running_add = self.critic.predict(np.reshape(self.states[-1], (1, self.state_size)))[0]\n",
    "        for t in reversed(range(0, len(rewards))):\n",
    "            running_add = running_add * self.discount_factor + rewards[t]\n",
    "            discounted_rewards[t] = running_add\n",
    "        return discounted_rewards\n",
    "\n",
    "    # save <s, a ,r> of each step\n",
    "    def memory(self, state, action, reward):\n",
    "        self.states.append(state)\n",
    "        act = np.zeros(self.action_size)\n",
    "        act[action] = 1\n",
    "        self.actions.append(act)\n",
    "        self.rewards.append(reward)\n",
    "\n",
    "    # update policy and value networks after every episode\n",
    "    def train_episode(self, done):\n",
    "        discounted_rewards = self.discount_rewards(self.rewards, done)\n",
    "\n",
    "        values = self.critic.predict(np.array(self.states))\n",
    "        values = np.reshape(values, len(values))\n",
    "\n",
    "        advantages = discounted_rewards - values\n",
    "\n",
    "        self.optimizer[0]([self.states, self.actions, advantages])\n",
    "        self.optimizer[1]([self.states, discounted_rewards])\n",
    "        self.states, self.actions, self.rewards = [], [], []\n",
    "\n",
    "    def get_action(self, state):\n",
    "        policy = self.actor.predict(np.reshape(state, [1, self.state_size]))[0]\n",
    "        return np.random.choice(self.action_size, 1, p=policy)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 3)                 0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 64)                256       \n_________________________________________________________________\ndense_2 (Dense)              (None, 64)                4160      \n_________________________________________________________________\ndense_3 (Dense)              (None, 128)               8320      \n_________________________________________________________________\ndense_4 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndense_5 (Dense)              (None, 2)                 258       \n=================================================================\nTotal params: 29,506\nTrainable params: 29,506\nNon-trainable params: 0\n_________________________________________________________________\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 3)                 0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 64)                256       \n_________________________________________________________________\ndense_2 (Dense)              (None, 64)                4160      \n_________________________________________________________________\ndense_3 (Dense)              (None, 128)               8320      \n_________________________________________________________________\ndense_6 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndense_7 (Dense)              (None, 1)                 129       \n=================================================================\nTotal params: 29,377\nTrainable params: 29,377\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl8HGd9P/DPs5fu+7BkHbYsW/KV\nOLblxM7hOLYTAglJSENKuBIK+EcpV/srNIEWCi39tVAoBCiQchZowDEhCTka4it24kvyfcuSLEuy\nbq2k1e5Kez6/P+bY2d3Ze/aQ9H2/Xn5ZOzs7Mzs7M9/nfhjnHIQQQggA6NJ9AIQQQjIHBQVCCCEy\nCgqEEEJkFBQIIYTIKCgQQgiRUVAghBAio6BACCFERkGBEEKIjIICIYQQmSEdOy0vL+eLFy9Ox64J\nIWTWOn78+CjnvCKZ+0hLUFi8eDHa2trSsWtCCJm1GGPXkr0PKj4ihBAio6BACCFERkGBEEKILOqg\nwBj7GWNsmDF2TuW9v2WMccZYubaHRwghJJViySn8AsC9gQsZY3UA7gbQo9ExEUIISZOogwLn/AAA\ns8pb/wHgCwBoth5CCJnlEqpTYIw9AOA65/y0RsdDCCEkjeLup8AYywXwJQD3RLn+DgA7AKC+vj7e\n3RJCSNTsTjemnR6U5Wel+1BmjURyCo0AGgCcZox1A6gFcIIxVqW2Muf8Gc55C+e8paIiqR3yCEmp\n7lEbRqYc6T4MouJQxxhO9kyk+zBmlbiDAuf8LOe8knO+mHO+GEAfgHWc80HNjo5Eze50Y8LuRPvQ\nlOr7w1MzmHF5UnxU80PHsBWne+nBQ+aGWJqkPgvgMIBmxlgfY+yjyTssEoupGRcOdYyhrXscPWP2\noPe9Xo4zvZM40TOehqMjgcasDnQMW5O6j1O9EzjcOZbUfZC5Keo6Bc75YxHeX5zw0aSQ0+0FY4BR\nP/v7701HmQNIZk6hfWgKFflZKMkzRf0Zj5fD5fEi26hP2nFlIqk4Y2llftL2MUrFWSROs/+JGKcD\n7SN48/JIug9jzugZs+P4tdhyIid6xvHWldEkHVGwCbsTuy8MweZwp2yfhMw28zYoJJvXy3GmbwLT\nTv/UucvjpbJ90aTdldL9DVpmAABmmzOl+yVkNqGgkCRjNieGLQ683TGK3ReG5OVHusZSmjqeLbxe\njl6zHZzPrT6QY1YH5UwUhi0z6Bi24u2OUc3quJxuLwYmpzXZViZqH5rye4YkW1rmU5jPHC5vug8h\nI/WY7egYtuLy4BRuX1Y+Z+oZpPqD7SsXpPlI0s/p9uJM36T8OjAXHa+z1ycwbnOhJNc0K6+bIcsM\ninKMIY9drfFIMs27nMKMy5PSqEui4/b6gqVlJrXFSiQ1DrQnpw5PSmh5Z2Eu0+vlONs3iRMx1scl\n07wLClbKysdkxuWB0z33cjd2pxu7Lwxh1EqtdAJ1DKe2uGI+k8LYjDtz6hnnXVAgsXnrymjSUnjp\nNDkt5EYGJ2fSfCSxsznc8Hq1SRW7PF5cn/Avj+8eTby4YtzmxLnrk5FXJBmHggIhGYhzoeI98OHv\ndHtxuHMMFwctmuznfL8FF/stmNK4yO5U7wQGJ2dwsmdcDsCZZtrpmZWJgmSb80HB6+XzvsjIJZbX\ne+deKdCc1T85g8uDU7g6ZvNb7hGDxIRGzXmlosFkXRtj1szNMbR2mzP22NJpzgeFS4NTONI5Bofb\ng2HLDOyOzCm7i8aMK/bUjMPt8SsSmHHGd8dnWnm72+PF8WtmzVqtZDKPR3j4ezQqJspUbk/i0Sje\nMxRYV2Z3unH82rgmxzSbzfmgMGEXOip5vBxn+iZDDhiXqeJJzZy7PomL/RbYnYnlkE4pRpfceyn9\nFY/DUw6M21x4u4P6ecTK5fEmfD0kw+m+zBlIsGvEhnGbE6PW+d25MaOCgtfLNS/blBzqiH5wMKfb\ni7Zuc9w9jznXrsgqnn4NDqlIQMNEZrzFCzaHG8evmWdN6mtqxoXdF4YwLvZ6nnZ68HbHKA53jqWt\nFZZlxpVwp77WbnNM90CqjNsys74hGjaHG8OWuVcnkVFB4cqwFUe7zLiiSM1zzlPebn1gchoTdhd6\nzMGtMIYsM9h9YShswOges6MzYBTMC/2W9DXzY+nZLSAMKz1uc8Fsnx2pL2kIjOPXxuH1cnSOWDHt\n9MDmcKN/IvW9Zi3TLhzrMqM7wQ5MUrFpvK2W9l0eRlu32my889fhzjG/znhzRUYFBamVwjXFDdA9\nZsexLnPKx8kJZUAs35+aCZ0TUMvtpOOBkknO9E7Ouk5pniR3htp9YQjDU+FTmjNiTtGiUQueQyGG\n0zbbnXJRqxqPh2tWuZ0sLAmpn1GrA6fm2VwZGRUU1Egp7mg6d+y7PIxjVyk1IxUfZVqns4kwRQWp\n7oyq1blJNPc3bEltZX6oHG7nsBVt3ZnTqzZTnO6dwOiUY86NyRVOxgcFyYTdhbEIrWE8Hq5Zimo2\nk1quSLmTZNXTRCNTcwdXhpI7yc1c0Gu2Y/eFIbhSXB/EOce1Mducb3mVqWKZee1njLFhxtg5xbJv\nMsYuMcbOMMb+wBgrTs5hChfofJprVauREW0ONy4NpKfFVf/ENA0AGCOXx5sx/Wp6x4ViXIciV2Vz\nuGMOEtNOT0x1GUMWB64MWdE54gvcdqc76tzdyZ7xiMVy4fSNC8Ew2v3NtaHYY8kp/ALAvQHL3gCw\nmnN+I4B2AE/FcxBeL8/YXo+SVN+sgSMjxtvJJvAGTmVzznibQPZPZEaLjosD2vQajsWJa+M4EsU0\nmlqUZjjcnphz1oc7x9AaRxHtpcHoEyZSXY7b4/uShzrGcKQrutZTY1YnzvTGXwEs1Z0caB+J6jwn\nqwNc+9AUukdtkVfUWNRBgXN+AIA5YNmfOOfSnX8EQG08B9ExYkXrVXNGjzvf1h3dzZosyg5sk3ZX\n3CkhrTp+WeNIMUZrdMoRcysZKXXXMWyFQ1H/NO304LDYeVF6yNiiDFapKO93erzoHrXJZdaBDRh4\n3F2zIjt3Pb6gZ4/iGgocsVSLYkRlyn3S7sKxq+agIqZoEpeT9sSb+KZCz5g96XN5q9GyTuEvALwW\nzwelMm/lDzweJkvWa7YHRWetBghTUrZlyKSA1dptTiglBAhBJta6BmWdzpHOsZRX6o+HaR0jtQrr\nHrXhrKKZ4Pn+Sdgcblzot2BMvKb6zJnTEsxsdaJj2CofWyCp+G0iCTlprfuO2BxumG1ODE7OBKWw\nrWFa68Vz714emoJl2hW03UgP+0m7C63dZnQpUuCzIUCkkiZBgTH2JQBuAL8Js84OxlgbY6xtZCTy\nqJvh2rVfHpwKGvpBrU9BPHrN9rCVkIEToh+/Zk6o/FITIa5ptZtTcu76JI52xfZQD+zpGU+uw5pA\ne/+BMMVKyu/pVjxkpKKAsSh7qSajWWM0Is0F4MqwlmST0y4MBXTcOtw5hhPXxmMuTrkSY2p43OaM\nu0GJlItUBpM9F4djKhp2ur041Bm5GNYzC4rF1SQcFBhjjwO4H8AHeJiQyzl/hnPewjlvqaioSHS3\nQbRqU345hrJPQOiRGZhqj/fBMjA5jZMaTVEoCdefAhAu3CNdY5i0u+D2eBPO5gcOwxzoSOcYLvRr\nX1Y/H1qdRXvewuWyI/ErrhBvqcCOmADQetXslyNLhNUR2293PGBCGi1u/Ui5Zs59OYqhKMdQu9Bv\nQetVs19x5myQ0HScjLF7AfwdgDs555rOGXd1xIbFZXlByxO54DPd+RjLeC8NWrC8qtAvZRwoUpm0\ndcYN64wbrd1mMCZc/AuLc5Bjim9aw4v9FtQU58T12VhxzsFY9AFYyzzAyZ5xLCjMDrtOYBoplmKK\nrtHgB3H/xDQayoPviUCBD81AY1YHesx21StDWbEpJbRGppJbtzId54CNqbT30jBK8kxYVx99A0sp\ngaU2RIzXy9E9ZkNdaa5Wh6iZWJqkPgvgMIBmxlgfY+yjAL4PoADAG4yxU4yxH2l5cFdVbozgVAJP\nWpkgR+aVNyo7H0ll41qlvKWv2j8xrZo6jF3yimJmXB7suTismjPhXKh4jqYeiHOga8Qq12dFW7E7\nZnVGPO97Lg77vd7fPoK3oxx/SNnyRmsneyYwZnWGLecHoht3SxoKJJE6vXjHGAOAq2M2eWh4wH80\nBKUJuzPhesdxmxN7Lg7H1X8i8Dz1jU+ja8SGa+LQ6OkqtlQTdU6Bc/6YyuKfangsQaKpB9tzcRi5\nJj0WFIVPtcWjZ8yOnjG76qTr/RPTqCjI0nyfkUTbLE+iZScttSy22+NNSYVz4AO+b1wIBgMT00E5\nE6lvhl4X+UaTysW9HCjPNyW1U5vHw+HxzK6ihEj6xqdxdcSW8GQ1XSNWNJTngTEmtzKKJkAr6/gY\nC52raeseR01JDsryTAkdJxDfXNAXBiwYnBSKnfKzDXLLvUwcJ3LW9GhWI7WDj6aJXCK6RoIfFMnO\nUoeSzl6eamPfWGbcIc9/uMq7aCrqlA4HNAeWijlsYX77WM4V5zzmCk/iK2JKtKlz14gNI2LrNimX\nOjWT2CCEgWMWJasFIYd/sbZlRhjeXdlkWwqaQ5YZdA5bg/ohZZJZHRQiDQVsd7oxHSFrGs2Do2tE\nvQOJMnU04/LIc+cmq215MprdxircoGmBAltqKWXaZEexnNlejVq6xeNk7xwen0ilGWsiRaPhrj8t\nudxeHL82Lg/a2TViw7TTE3MR4IzLg+5RW8ThfJItoYrmZLs+kdjNF8348WevT6KiICuuylFl07u3\nrsSW8j3TN4GCbGNUFYeSvZeGI6+UZG3d46rFaenicntxSINe2j1jdhTlGqNbNwlBIdoy5XDBdMLu\nlIvVJK3d5pRV/CcqA9I8CXF4PACiu4YkytyE8hmSznsso4NCKuYUHp1yYHTKAbvDjaWV+cnfoWjY\n4sCwxRFTUNBKJo7VMhTQe5hDyMVFUy+Q7OLDQJGKlKM9bi1ZHW7VUU4n7a6MGXY+knPXJ1GVhLpB\nyYTdhQl74s1oBzWcWEcqbYimdCGwCDVZMjoopNK1MXtSeo1mohMRmiwmyuvliKGlKCanXUEtUJxu\nL97uGEXTggLUl6Wm2Z7awzPWOsUZlwdvXRGOO1aJFA+mcwiWVMqEkVMjFX3GMyx7NNdZqkZVmNV1\nCkrKGyreXoSzJUWVbpFuzL2XhnFCZUTbUPNjq5XRS3VBQxr2Fo+ng2Ngr91IpGac8aQm4y0ejKWe\nR2vxtMQJJ9J4WvsyoAg1kng6q2VSy/c5ExSURQjxjOKYLpYZF/rGM7clgppobsyM7GSY4I2XyMeT\nOSdBOmdEuxqiEUa85kPP9EyXEUEhk6Jkqh3rMqdtvgMAGLUl1tLBnYKKn3SmhJXUmiYHOt2nPudH\nps2CR5JAw+dYOovJMiIokPRJNKWX6GitoSiLALWaJjLRGy2axIv08E92ijeRXsCzTTLGygoUaYyw\naJzXcP6NdBaTzdmgMBtHJyQ+UgemTMxFhnogh6soTtb1mOqpMpNN7RQm0oEtlMAcrhadyTwh+iWc\n609OwilZ5mzro9lUr5CI+ZRizAThirLCVRRHSu3GM8bWsGUGZ/om0zLcSrKc7k3NlLvjtuAgrcUQ\n+GrDfcy2BixzNqcw25yIc8jsWDvNzTaZVvGoVVFWoP44xg6SJuZJ15Arc40W1WMzLs+sn5ecgkKG\nMEc5CcxcNNeKQOIRT9NOyiVmHuccuJbnTFBIRSsYkhyuJA4TPZdFO5scIbGYM0FBrYyQEEJIbOZM\nUCCzV6bVG6RD5kyxQua7WGZe+xljbJgxdk6xrJQx9gZj7Ir4f0lyDnN+yYTxXUhqUVFQ4hKdX1wL\nmTxPQrRiySn8AsC9AcueBLCHc74MwB7xNUnQbBjfhZBMk6yOlPNN1EGBc34AQGDj/wcB/FL8+5cA\nHtLouAghhKRBonUKCzjnAwAg/l+Z+CERQghJl5RVNDPGdjDG2hhjbSMjI6naLSGEkBgkGhSGGGPV\nACD+H7IwnHP+DOe8hXPeUlFRkeBuCSGEJEOiQeElAI+Lfz8O4MUEt0cIISSNYmmS+iyAwwCaGWN9\njLGPAvhXAHczxq4AuFt8HbNMaEpGCCEkhlFSOeePhXhrW6IHQSNUEEJIZqAezYQQQmQUFAghhMgo\nKBBCCJFRUCCEECKjoEAIIURGQYEQQoiMggIhhBAZBQVCCCEyCgqEEEJkFBQIIYTIKCgQQgiRUVAg\nhBAio6BACCFERkGBEEKIjIICIYQQGQUFQgghMk2CAmPsrxlj5xlj5xhjzzLGsrXYLiGEkNRKOCgw\nxmoAfAZAC+d8NQA9gPclul1CCCGpp1XxkQFADmPMACAXQL9G2yWEEJJCCQcFzvl1AP8OoAfAAIBJ\nzvmfAtdjjO1gjLUxxtpGRkYS3S0hhJAk0KL4qATAgwAaACwEkMcY+2DgepzzZzjnLZzzloqKikR3\nSwghJAm0KD7aDuAq53yEc+4C8DyAWzXYLiGEkBTTIij0ANjIGMtljDEA2wBc1GC7hBBCUkyLOoWj\nAHYBOAHgrLjNZxLdLiGEkNQzaLERzvlXAHxFi20RQghJH+rRTAghREZBgRBCiIyCAiGEEBkFBUII\nITIKCoQQQmQUFAghhMgoKBBCCJFRUCCEECKjoEAIIUSW9qAwOe1K9yEQQggRpT0oON3edB8CIYQQ\nUdqDAiGEkMyR9qAwNUPFR4QQkinSHhS6x2zpPgRCCCGitAcFQgghmYOCAiGEEJkmQYExVswY28UY\nu8QYu8gY26TFdgkhhKSWJjOvAfgugP/lnD/CGDMByNVou4QQQlIo4aDAGCsEsBnAEwDAOXcCcCa6\nXUIIIamnRfHREgAjAH7OGDvJGPsJYywvcCXG2A7GWBtjrG1kZESD3RJCCNGaFkHBAGAdgB9yztcC\nsAF4MnAlzvkznPMWznlLRUWFBrslhBCiNS2CQh+APs75UfH1LghBghBCyCyTcFDgnA8C6GWMNYuL\ntgG4kOh2CSGEpJ5WrY8+DeA3YsujLgAf0Wi7hBBCUkiToMA5PwWgRYttEUIISR/q0UwIIURGQYEQ\nQoiMggIhhBAZBQVCCCEyCgqEEEJkFBQIIYTIKCgQQgiRpT0oeL3pPgJCCCGStAcFQgghmYOCAiGE\nEBkFBUIIITIKCoQQQmQUFAghhMgoKBBCCJFRUCCEECKjoEAIIUSmWVBgjOkZYycZYy9rtU1CCCGp\npWVO4bMALmq4PUIIISmmSVBgjNUCuA/AT7TYHiGEkPTQKqfwHQBfABByJCPG2A7GWBtjrG1kZESj\n3RJCCNFSwkGBMXY/gGHO+fFw63HOn+Gct3DOWyoqKhLdLSGEkCTQIqdwG4AHGGPdAH4LYCtj7Nca\nbJcQQkiKJRwUOOdPcc5rOeeLAbwPwF7O+QcTPjJCCCEpR/0UCCGEyAxaboxzvh/Afi23SQghJHUo\np0AIIURGQYEQQoiMggKZ8wzOSWzf2YSajmfTfSiEZDwKCmTOy7ZdBwDUdv5Pmo8ks1X0vY68icvp\nPgySZppWNBOSifItVwAABZP0wAtnzaFPAwB2P9qe5iMh6UQ5hVksx9oDndue7sMIyTQ9jOYTXwPz\nutN6HEbHeFr3P9ts2P1eLDn33XQfBkkTCgqz2G2vbse6A3+R7sMIafmJf0Rdx69RNngwqfvReRxh\n37eU3gAAmCy9ManHkW65li4s7NoJvcuKhV27AM7j2k6R+TSWXPiBxkcXPeZ1Y81bn0DB+IW0HUNU\nuBd6ly3dR6E5CgqzXPHoibg/a5oZRcOF/4z74SHzeoR/AfInhWKbwJT69p1NWHPw//gtY14XGi78\nJ3TumZh2nWvpwNbf34AF1/4YZi0GAOBsbl/ut7zxIFa2/T2Wn/gqVrZ9EUVj8V8b6VQwfg4V/Xtx\nyxsPpftQwmo89x3c9Ye10Lus6T4UTc3tu4SEtero59F47jsoNJ9JaDubXn8Xtu9aEbQ813oNAFDR\nvzvovYqBfX6va7p2ovHcd9B88p9Q1/4LgHMYHWaAhxx4FwBQMHFJ3MeeMGsJQUEfIUcRit5lVQ16\nmUb6fqaZMeF1BhctAoDOPY0VrV+EwTHht9zotKTpiGJTfe1FAIBhlhxvtCgopEGupRM1nb9N92HI\nDw3G/cv8mdcF5nVFvZ28qath32dRPFD17mkAQM3V59B86l9QNHYCd764EY1nvy2vs7BrJ7bvbApx\nbCzM1oWcUMFE5Dmgmk7+M7b8YZ38Wueexl1/WIem0/8a8bOZgjPhXLCAgFoydAiFY6c02AFHwfj5\nhDdTc/U51FzdhSXnvwcAMV1zGUE6vyzctTf7UFCIUU3Hs8hPsKzzljceworjX07sQBIt8vHjf1Fv\nfnET7vjj7X7Lcqa6UTzSGtfWdYqbfdNr94ZYy//7ZM2MAgAW9L4qL1t65t8BAAbXlOJj4ufC3pjC\ne5aSVRGPtf7Kf8OgKA6QglWVmCpUMjrMqOh7PeI2U086F/7ndP2bT+DmPY9iResXsW1nc8StlAwd\nxrbnlqPQfAZFo8flc1DX8Svc8sZ7UDJ0KLHDVFzDpYMHsW3XKhSOnYbLVJjYdlNGOn4KCvPaihNf\nwcYEyzrDFWPkTl2F3jkV8n0f7YKCaWYEjWf/Q35tdFlgCqgHuO21e9Cy7wMqhxG+eAcAisynUNMh\n9BHIm+pSfJbLradCVUbruC+XYXKKxQyKr85iOA+cadMCu3TwbWx+cSM2vXYv1hz6dFDxR9rJOQX1\nc1NzdZd83soG9sMoFjcFaj75z2Dci5t3P4INex/D6qOfBwDki0V2Oba+oM/kT1xEXfsvAe5FVfcL\nYB5nyMOU6poWXvsDygeE37949ASyZoRJuBxZZSE/q3dZseTcdzXJXVT2/i+y7IMxf046vzwFOYUb\nDn0G23c2JX0/AAWFpNC5p7H8+FcilzWq3LS3vvYObNj7voj7UBYNNJ/4anAFLee446VbUTR6MuK2\n1hz6NBou/hB5YsWwbxtetOx51P+hwb3YvrNJuPEBVPb9r/zW5hdvQYvKsRtcVqw48Y9By5ecfxpb\nn78JBqclqDhCbsaq+mDjQX/zMKk1rStc1x34CEwOsxykmCJw6dwzyA9RTGVwTMT18IlbhIDNvC6s\nPbgD6998XPV9qX9H0Ofk30QHcI6G89+Tcw0b//Qgmk99HdufW47Vx76Abb9fHXL/UrGjIaCids3b\nfwUAMDnMIT/beO5pLLnwA1RdeynkOoGKRo+jwHzOfyH34sbDn8H6fe/3W1zb8Rts39mE3ICiUb1z\nCptfuFnMNcefU8iyD8A4E/r7BVqguM+Sbd4EhULzGdUigEUXfyxEYLHcu3ikFXVX/lt+X++yYcPu\n9wY/MMOo6dqJ2s5n0RDQrE/ntsM0PeRbEOKmVbsZi0dasX1nExrOf19IXSs+W9fxG9R1+M9rVDB+\nHlkzo9iw98+DtmWcGUPJ8NGg5ZzpsaDnFfn10rPfQvHYKdz50ibfdxBTZs2nvo5sa69cqQkAJsd4\nTK2hqrv/AABouPD9oPJv3w0XHBTUcwehb8ym0/8GQGhqWTawX069FpjPRW7tFMX9Xjb0Nsr79wIA\nVrY+iY1/elA193DHy5txx8ubI29QRY61J3TxHecoGTrs9xqInIvatksoTsufjK2zmtQwoWTkKCr7\nXkfj+e9h/ZtPhFy/rv0XqFQUA0oYD07llw69Lf8drrWYziPkMHURcgoLu3bhjhc3AZxjw97HcMvu\nh3GjGHSEYxDu+2z7gN/nlp/4KgBg0aX/8h3b4Nuo7H8DJudEQKu96ILCwq5dKBLvjztevhN3vrQx\nqs+l2rwJCjfvfkTO/io1nn8aAKATK1tb9n0AzSf/WX6/ZOQoisyn5fJsSY61BwBQ0/lblA286fee\n9IALfNBteWEDNv/xDt96iimtDY6JsFltqeim8fzTWHb6G0E3fLatzy9V7THkyn9XX30eq4/8jVwX\n0rLv/Vi//0NB+8ixXsMNR/5afp1lHwpaRxmMbn91m18qOVY59n4AwKL2X8DgDmjvLX6X7Okh6J1T\nKBppC3pvReuXVH9TQEgFLzn7naDmgmsP7sCyM/8O48wYbtn9MG5/ZUvISlODY0J+z+ScgEms5wi0\n+ujf4qa3PgEAKBGPU+8JDjZqyza+fj+272yCwTkJcI76yz+HccaMLFs/tu9sQu2VXwEQ+qSoFt9B\nyK0pU/tSw4GiUd8MuaWDbwd9Ll5SoqW8fx+ypiPnfJpP/QtuPPw5NJ75FrbvbJL7lSiLt7LFa6F8\n8IC8TMc9uGvXaiHRFnAvKT9baD6DxoD7U7L8xFeQ5RiDzjMtL6u8/gYAoXPloss/lbao+vmSkWPy\n3+sOfASrjj0JAPDqjPI9WDJ8BJtfuBl6lxXZtj5s39mElcf+zn87Q4exsu2LqqUAxSOtQYkIg3NS\nuKfTQIs5musYY/sYYxcZY+cZY59NZHvL276MNQf/D9Yc3BGxU5IWpJRG2cCbqj1fOdMDCG6hs1bs\nNLbi+Jex9uDHAz7ju8Bypq5B77JC53EEp2o4h945hbr2/8aWF2/GOpXUFvO6g26IfEtH0LK6zv9B\n49lvAQBM0yPIUuRIVrU+iaqel7Fhz6MAfNn24jH/oqW1b/n3HajuUcua+wejRIJCOMvOfEP+e1H7\nz7DBL3svHEPN1ecUB+L/+aprf8SSi/8ZFMwBIG/yslxkYXKYccsb71E9hvVvfhjrDnxUfl3T+duQ\ngUGSNTMMAMix9YbMhZimR7B9ZxOKRk/KqfQtL2xAwfh5NJ3+f1h17PNyE9vlJ//J/8OK393gnMTS\n09+Qm/5KysSinMXiA+/WV+/GugMfCXvc0XYUK+v3NSU2uixoPvUvUX0OABou/Vg8bguaT3zVrxlx\n5fU/qX5G7xUSSqGa13Iw3Lz7ETRcegZ65xSY1yWUCMjl/cIjTq0F3I2HPoWlYus2HXfj9j/eEVS/\nkmvtwfadTX45BgDgOgOk63Dp2W/D5JxAbcdvcPsrWwEAC8VcsES6LgDIRa8AAK8HLfs+4Pf7lA4e\nxJYXNuD2V7ampQ+EFjVvbgD/l3N+gjFWAOA4Y+wNznnsTXQ4R22Xr6lm0ehxjC+4VX695Nx3seTC\nD9Cz9ENoX/cPGhy6z5pDn1ItGu/lAAAgAElEQVSt2JIqJxn3oOG8rzgo19qjOnxD/vgF5IgDsAEc\nt712d8h9MnCsfevjcpFLyWhb0Drbdq0MWlYyckyluAVouPQMOm/8W2z+422q+5NusEQEVl5KRTNR\niaHFVLYiqCkDHCAUz+UFFLFVX3sJ52/xBYBKsVVQncogeDqvCyaxMjOUotETch8ISeP5p1HbGd1I\nqy37PoDx8haYq27H1RWfgE6RC5R+n+aTXws4LrFYa+IyzAv8W39Jtj+3HLvfexklw4flIpup4uVh\njyUwaKiJtqOYMuHgzCoNW+4fit4zjbqO38ivHdkVcuVyKLWdz8Kjz0HfMmmm3+Br6a4X1qNz1WfQ\neP5pVF17CWdu/T6k1MJdL6wPWr84oHlu9vQQFvS+pvqdlp35pt/r8oE34dVnAQBy7ML9vkxMlMnf\n02WFx5gftK3mU1+X/zY5hCBUKOZIm4//o981q3fbVbeRTAkHBc75AIAB8e8pxthFADUAYg4KC7t2\nhn1f6npf3/GrqINC3sRlbPrTu6NaN8uh0gpDTIGWDR2SU2CSNQEpawB+LZMi9kXgHIVj8XYcU3/A\nrtsXXCykdNvLW+LcX/j9Bq8WHLRMitRSLKp6XvZ7LRX5haJz24M6xymVjLYF5DyEJrceQ578OlRl\nf6SHV+B+Skbb0HjuO6rv2wsa5IcBAKx5+5PiPobRdPr/hdzu9uf8m5PqwhQ7JpNf02AAS6NMIFRc\n9+9oGM05lR7KvqAgqL/yC7/XUk6ufPAgtj6/Bh59tur2dO5p1eUFExdQc3VXxOPReV0R6zPuEvu7\n7HnkQshc4+aApt/BiRiO5W3aJoAj0bROgTG2GMBaAMG1mFEoG3orcIvCf14PKvrUs5eRNFz8kepy\nnceBnKnuiJ9vOvn1kO+VBzSjNE37X9yRU+ZehHrIrj7816rLJWo5BQAoHQl/6qVy/HiF2q+SwTmJ\nRZd+Erxva29c+1Qri1fTfOJryLIPoLr7hZj3cdtr94TMYUXrJkVRUzQCg108qW4goJlvgAUB+9BS\n4ENxsVw+H164gBctvVgHlW/p9Fse+FANde0UhejEF01AiJXRYcbK45Ef7GrPmlXHnkRt1+80P6Zw\nNBs6mzGWD+D3AD7HOQ9qi8kY2wFgBwDU19erbmNBQEegplP/grHqzXCaStF0JiAVwnlQhyWd244l\n57+HxZd/ij1/dg5cb0JV7ytQc8Phz6JCbDGiprr7Dxipvksov49SrA+Vqp5X/Nrh+73X+wq6Vv2V\n6ntA8sryI9nyQksU62xQXR6YOtdaXcevg1phpVJgIkErW55fG/dnbzjyNxoeSfqt2/9hXF7796jq\nfS2h7axqfVKjI4qsMMre3/VXfhm0rGxIuwYC0WJcg56xjDEjgJcBvM45/3ak9VtaWnhbm1B+vvuC\nr7w4ls4ZV278Aq4t/xgKxi/AaSqGI29h0Od3P9quuizWfWWiNx84krFN2gghycG+ajnOOY+cMkuA\nFq2PGICfArgYTUDQyrIz30Dh2Gnc8sZDuOOVLanabcYILM8lhBAtaFGncBuADwHYyhg7Jf57Vywb\nKB5pxV27Qvd8DKVoLHxv3frLP1ddvujij2PeV6YJ16qJEELipUXro7eQ4IhQS898K87mkr7d5qqU\n/atVaK0+8jdBFXyEEEIEGdGjuViDsWkMUc6ARAGBEEJCy4igEC9lJxCv3pTGIyGEkLlhVgcFpdVH\n/jbdh0AIIbPenAkKoYb5JYQQEr05ExQIIYQkjoICIYQQGQUFQgghMgoKhBAyC5zZFH50YK1QUJgn\nHNmVSd3+VPGKpG4/Hn1LIs917WXx99+8sP6fIq80R0hjhpH0KQ0Yuj9Z0h4Uwk1BSbTjzC6DM6vE\nb9nb79qN8Yqbg9a90BJ6uHA1Jzb/DK1bfwdzxS0JHaPWLrV8LeI6/Q2PxL39/sbg+a8zyUj1Fk23\nN6aY8Coca+HSoGUH739TZU11LmNh1OvGymUsSNq2lS60RD8jXbTMVYkN7R6ttAeFaMfKJ6HZ8+oi\nruMx5ODAg0dxrUmYRrRz9ecwnV+P43cFDzU9sFh9esq337Vbdbm56nZ4DdmYyVsYw1Gre/PBoyEf\nZpfWCmPSmyv9R4e9cqNvnub2NU9Fva+h2neqLu9Z9kTU2zjw7uQMl600FmIWtkjcGj8AT97hmy8h\nXALg4vqv+f0OR7f/Ho7cagzUPxDVftq2RpicKoJQv9/Zjd/G0XtejHo7wzX34PiWXwUtP3HnzyP+\nJv1LYktsnNj8M3nq0FA84kxvyZb+oBBi7tVM4jbkRrXemw8cxv6HWkO+37M0/KxoALD34TNo3fos\nbAUNAPwfXNdDpGpP3y4M8BcuJSfNQNW5+rPoXPVpdC//eMh1hflng03nq8+DIbm64pOwlKzG6Vu/\nDwAYXrgNux+5GLTeRFno+QHchjxYSteovidN7h44d7dHn4Nzt3wTrVufRU/TE7i09ss4tl2YLOXi\nuq/6rSvdeI7scpzd9J2gOTkAYKjuXr/XXSs+GfJ4nTkLQr7nyK6Q/z5072s4tu25kOuG07f0MUwV\n+c+2dnbjf0T8XKjzePC+/dj93kvobv44Dr/DN+zLRPm68BvU6dG+5imc2PxznLjrVxiu2Q4AmCy9\nUV6lZ+mHMFm2Fn1iLsqjz8ZU6Q0AAK7TRzxmALAVBec0YtG+9ouqy4fq78dMXm1U25gqXo4zt30f\n45W+4Oc0FePqik/AvOA2eAw5fuvb8xcBALpWfgr73hP7sD3mqtux55EIk1VqMM1BNNIeFAxpmJg6\nFpbildj/sPosTQCw/6E2DNbdh70Pn4IruwxuU5Hf+5PiDQFAntM1HK8hG5Pl6zGyULjhLCWrsPvR\ndrz5wBFcWu97wI1VblJ8imP3o+24vPbvg7Y3Wn2n+P8Wcfs5uLrq0+A6o7zOmw8cCfrcwfsP4MAD\nh7DnEWGCkMD5q20FS4I+M12wCMfufh4jtfdg96PtOHP7DwGdHvseOu63njO7Ake3P69+ApgOY9V3\nqL41WC9Mq3p9ia/Yprv547i+5FEMLnoQk+XrAcbQt+yDsIgPqutLH/PbxrXmj2Lvw6fw1n37VQNC\n56rP+L2259Wh64bPYe/Dp0PmlJQmym6S/24VU7y9je+HvbARM7lCTmqg3jc97L73hB7pd7DuPlhK\nVmNk4Ta/5X1LHsVQ/X04uzH8SPU84PtdvulLOHTv/8KRtxBgOnSs+TxsRcK8Ij3LnsDJO34Cr86I\nt961R21zwnrNH5GLMaZKhJGNB+vvl99vX/cPgE4vz20+qQhMV1f+lV8ACUftWlbqbvaf5a5vSfii\nvIvr/jHs+2/dtxduQx76Fz0Ee14dLt/k2//p24RpgA+980/ovEGYtKin6Qm/z0uJjcFF7w6aU3m8\nPHh+aL99S+eb6XDwvv0h10to1NEYaDbzWryMzvGk78Ojz465mMppKobJOYFTm4OnlZSYKzfCbSrE\nuU3+qbY9j1yA3mVFrrUb1qImbH1eeFBcW/5x1HX8OuhYPPoc6D3T8kNEIE57KV5sruxSAEIWuLLv\ndb/U8kxutbCqN3g2Nim16gmT23Fll8rnqLdRmB3NkVslv7//oTa/gDZecTOO3/XrqCcq8ph8xRjj\nFTej/aYnMZNXi70Pn8HW5/0fEpzpYCm9EYfufRX2/AYweHHbK1uRPT0EV1aJXOEpzZzVsebziOTS\nuq9g8aVnkG0fwPWG98KrOBc84Fa7uvKTflM1XrlJKAbxGnIwnV8PR1YZshxjqhXrx7btRJ6lU54Q\n3pVV6ldB68ypwNHtv4etcBl6l30YWTPD8BjzsPvRdqw5uAMVA/thrtyI0uEj6Fn2ONrXfkn+LBOn\nbb24/mty8d5Q/f1wG/Ox9uAO3/ktX4+S0ePyp5RcpiLYC4ODufIY9z5yHszrBgBYCxuDprtU6m7+\nGDgY+hrfj+ZT/mXoXG/Cse27/BIP0/n1aN2+S3Wk4p5lT6D+yi9wdPvvAQC9yz6M3mUfRsX1N7Dm\n7b/CeHkLSkbb5PVtRcv8Pt/X+JjqtJUTZetgLW7G9aXhZ/2byavF/ofVA/RIzd1BFe0TFRswWPcu\nVPW+CrchD/K5VkxX+9Z9+2CaGQHXmXCLYu526dkiv87xNQJxqBTBTpSvQ/HoCUQ9P3qC0h4UvLro\nB7KbKl6OgolLAICR6rvCTs7uLzjGHtv2HG7e817VtUcWbsWZW7+HbPsAnNnlAIC2Lb9Gy35h0vBD\n73wd2bbrmFSkCpW4zgB3VjEsWf7vu7JKsO/h09i6ayV03ANnVglMjnH0LvsgBhY9KKfaAN9cyIGp\nvaH6+zFUfz8azn8PFQP7AUBOmdgLGsSU5V1oPP898ViEHEG4oAAArdt+h8q+N9C1+jNB77lNvoq/\n/Q+1wqMXss4HHjgExDgt6Jlbn4YrSwhwXoP/pOqtW38nB0G7WFnJoVccu+9cjCzchuKR0EV1Sn1L\nP4DrSx5F7lQ3pgsWh1+Z6eASK+R7ln4II2IRieTgg4dhnBlTPZ+WspuQa70GABiv2ACPMS9oHako\nxVLmX7Rz5aanwMAxWbYWpcNHgn53qehgonydX4Aeq96C6dyFyLH34/A7Xkb5wJu+oCBuY7L0BuRP\nXIZ5QXQVlVxnwKnbfwRLyQ2ovP4nTOfVqK+nN6F75V8CEHKWgYNSWkLkCs5t/DZ6mp7Azbt9xaHt\na7+oWuwzUnM39r3nJDzGPDkR0rPswxisux+rjgkJg8H6+0Omotu2ha6fsBUsQd5UF7wsumKtQNai\nZqD3VfQu/SAq+oVcJFMU8czk1WAmrwYFAdNxesWiXK/OiHMbvx2xBIFLBTopKj5Ke1BwZpeFfG/3\no+0oG9iPtQd3wKMz4eg9L8kXRqhRUQ+983Xc+to7gpb3LHvcbw7UwJtSyWUqAdcZ/crQp0pWAQDO\n3/yvsBc0wC6W+Uej/ca/Q8GkWLbOGPqWfhD1V34pZ7HB4RcQAOXFpV7Cd3XFJ6F3T8NW2Cgv43oT\njt39PMoGDsjLrtz4eTiyK0JWqkqsxStgjaJZqbJ4TAqY0fDos6D3OOSAIDl5x0/gNuZjMkx59qk7\n/gsLel6BQ1F+f/r2H0a9b0AIjoGpSwAYqdmGus7/wanbfwSbGIjsBQ04uv15WIvUc0KuMNfsVLFw\nnUTTHFbJXtCAU3f8FxZ27QQAuE3Ffu/3LPswVh7/B8zkVAd9Nkesa+FM79eaTCq66V7xCYzUxDYp\n0+jCrQCEgBoNZc4yKooH3KF3vh5mRQQF1/aAoiWpvkzprfv2BeUCJYN196Gq9xUM1t+PxvNPh5wn\nPRIp9yYEX+k+9QatFzhLonS8LlMJhmuDn1USl7EQRpcFUg6BzaacAmPsXgDfBaAH8BPO+b9G+9mi\nUf8sm1dnhM7rkl+PVW/xy7odvP8AGi78J6aKl2NBX/DFZC9owJF7XkKh+QwAHVa2fRF6zzQcOdG3\n01ercJOy+fHoWe5f/gk5FyClUIIvpMmyNcAVYKokxINap0fHmi+ovuVQPKw9xnxcXfWpmI9Za/v+\n7Kzq8rHqzRE/O51fL6dItWauugN7HjnvV8cCAFOl0c8E2Lr1d3DkCMV0tqKl2PvwmaBcULT6F/8Z\ndF4Xrjf452L7G/88ZBNYe/4iOYdiKVsDLzPAWrwcU6Wrsffh0/AGVIpmApcY9PqW/HlMCSylU7f9\nEDe9/ZeYzqvzK7YBhFR6KOc2fhvdK3aAMyMaz2vTIWwmtxr5liuKe9onx9oj/3294b3oa3wMt+x+\nGDqvI2hdJZdJCgqSWRIUGGN6AD8AcDeAPgCtjLGXOOdhq9J7zXbkmvR+RUD7H2oDZzrc9YfQqUZH\nbhUutXwNZf3BRUd7Hz4DALAWL4e1eDkMTgtWtglZ0qprLwUfw9IPwugwo6r3VQBCszB7/qKoWygk\nqm/p+5Fj7UH3iuAH3lD9fZgoXx97CgzAtNgSon3Nkwkf43wQGBBiNVnu35oq3oAAANDpo06dS64v\neRTLznxTzrntfa/v1svEgAAIjRJat/4OFjEHHo/Rmm1o3fosJktvQpH5NADAHVDJq4oxWItXIDdM\nfUlsGM7f/A1U9O+BXZFzl4xVCQmfwfr7cXHD1+X6QLX+HEon7/wFKvreQLFUlzKLio9uBtDBOe8C\nAMbYbwE8CCBkULDMuHB5UMhSrRTrFMbL1/uVXUcytvAuv9fWwmVBN6OUfXQb8pCnMl3n5XVfBgA5\nKJir4msPHispG+jR5+LihtCdXOIJCEBiuRoy+1xr/hh6mj4SsilxpgoMppGcveVbyJ+8HLANoWWP\nVA8US7GdyWGOaf9BFA9pV3Yp+peo11E6cqvw1n174cgR7mevPktodh4hKEzn16Nn+UdR/PbxsOtp\nTYurqAZAr+J1H4Cou7aOVt+Jhd3Po+NG3yQ57WueClmeq6Z16+/Uh1lQVNZ1rfoMlp77D0yW3oCB\nReqdswiZlRjz1U/NYUOL3o0hvFv1PanYONKDVsmbYA6xp+lx5Nh60N38sYjrBpY+TIZppmopWYVC\nReV016rPIM/SifGATpvJosWVpFabE5TPYYztALADABbULvYtF5u/uUy+IRh6mj8S1Y7ffOAwKvr3\nhkxxePQ5cGaVon3Nk3IqamDRQ+hb9kG/9U7f+n25DTkhZHayFi+PaX2p/N9SEn39kZLHmI8LN/9b\nXJ8Np23rb/2anFuLl+NwhMp4LWkRFPoAKMdZqAXQH7gS5/wZAM8AQNPqNXLQkCqV45lj2ZVdFjLL\nJmxcjwMPHpEOAB5DntyZS2mk9p6Y962JVPVGIYQEkYKCWuVwOnn1WVF1dE0WLYJCK4BljLEGANcB\nvA9A+J4iCjqvMCBeolm5iBjDaEA9RPqkpsKIEBKatXg5ri7fgeuNj0VeeR5JOChwzt2MsU8BeB1C\nk9Sfcc7PR/iYTCeOkspj6MQ2V4RqR00ISQGmQ6eiLpMINKmd4py/CuDVeD7ryynMo6CQoqZlhBAS\nq7QPiJey4qMMwqQelBGGyiWEkFRL+1OJiRXNiXYgmk2Kx4Re3Nm2oPp4QghJq7QHBZ3HCY/OpDqM\n8VwljUQaa+cdQghJtrT3eNF5neBxNEedza43PgZrURMmK1rSfSiEEOIn/TkFr3N+VTIDAGMUEAgh\nGSl9OQXuBcBQ2/ls2g6BEEKIv7QEhULzOWx/LrYu6YQQQpIv7cVHhBBCMgcFBUIIIbK0B4WZ3Grs\nfu/lyCtqbElF8Py5sSrOnT99K5LhhtoiGPTzpykyIbNBWoKCpXQ1dj/ajt2PtuOt+9+Mu4/C9pUL\nsLGxDCsX+ibnyTFFN+KhXhe8z+aqAr/Xa+qEKQPLC7JwZ3OF33u3LClFy2L/+YYBoLbUN9PV8mr/\n7VUWZmFLcwVK8xNrbbW6psjvdVVRNgqyfdVDC4vVZ9uqKIh/5MWGijxsUHzfpgW+76ZTXEUti0sQ\njeaqAiwozMaW5uinSQ2nLN+EjY2h506ORqjzs33lAtxUX4zCHO0TARtUrqFQ8hW/sfJYYtlGvCLt\n48baorDvJ0OqEmV5WWlvuZ9SGfVtFxbnYOXCQuy+MOS3fGllPjqGrSjONWLCLvSAlh7Y+VkG5GcZ\nUFWYjWPdZjRW5ON074Tf500GHRor83Gx3zffaV6WAXodg8frG4eorjQXTo8XdocHSyrykJdlwLpF\nJSjMNsCg12H7SmHieK+XQycGlU2NZRi3O3FpQJhJbnlVIZZX+YJUdVEO9l0aRk1JDlZU+88sl59t\nwIqqQrR2CzNAbWgoRetV4e/NTRVgDLg6akPPmB1Ggw4bFpfA5vCgNM8XVPQ6htU1Reg12+XZ7Jqr\nCtA/Me23r7X1xSjLz8KwZQZFuUZ4vByHOsbkfZkMuqDzrtxHY4VvmsOqomzUl+WifUjY39blCzBk\nmYFJr0Nxrglr64txssf3G6yuKUJJnhGjVid6xuywOdx+N1p9WS56xuwoyTNh3OZUPYab6othnXHD\n5nRjYGIGgPAb2hzCfBxraouh0zEU5hhhmXahZXEJ2rrH/b6D8rcOVJBtwJq6YkzaXWjtNmNxeR66\nR21yQqE8Pwv5WQYc7hyDx8tRXpCF0SnfmPeLynIxMe2CUa/zW15VlI3ByRn59YqFhcg26DDj9qIo\nx4j8LAO2Lq/E9YlpXB6cwuqaIlQUZKHXbEeOSY+zfZMAhGuzuaoAx6+NY9zmxKqFhZicdmFBYTa8\n3P8abijPQ/vQlN9+JcsW5KMw24jOESuWVuZj1OpE96gNKxcWIi/LALvTjfPXLUGfK8o1ytd/54gV\nV0dsAICakhw0lOch26hHc5UXlwenUFuagz6zcP01VxXI12VlYRaGLcHzEi+vLkCP2Y7FZXkoyzfh\nYPsoACEnKX1/NUU5vueBUqTPhbKqphCVBdm4MjwFo16HMasT1UXZqCvNxfDUDM70CttcXJ4LzgGn\nxytfi4GkazoaTQsKUFuSA4fbC7vT7XfvpEPGBIXbl5Uj2yik8g16hoXFOfJJXVyeh8XlQnGPzeGG\nw+31ezACgE7HsHFJGdwe/wm8F5fnYVFZLpxu3/KiXCPK87Nw13Ihlap8GCoffgCC9iPtS5KXZUCe\nGJTUHjl6HcPmpgoYVYpJllbmoyjXiE2NZRiecqBITP0V5xphMgjJ79oS4TwYdAy5JgNyTcJPdtvS\ncjDmy/EsLM6B1eHG0sp86HUMi8pyUVmYjYIsAwYtMyjLF1LBlYW+KUulmzzQ7cvKcbhrDBX5WVgZ\nEMiUn5F+JwBYoNhuWb6QszLq/TOiNcU5WFiUjclpF4pzfee1NM+EnjE7sgw63NFUDs4Bg46BMQaX\n+HtmG/UoF7/DqoW+VKn020m/yc0NpXC6vTAZdH4P5E2NZbg2ZkeOUY/CHIO8/54xO9qHpuRArnz4\nLa30vxayjXrctbwSVocbOUY9Rq0OZBv18u8m4Zz7fcf6slwc6zKjsjALNSq5OJ2Ooa40F4U5Rnlb\n0vW+YKX/FLM31BRhxOqQrzsA0INh/aISuLxeVORngTEhobC6pggjUw6/RNKiMmG7LXlCyr8w2wiT\nXofqomwwxlCUY0RFfha6x+zoG7fD7eFBue/GinzUluSAc8j3LCAEpLrSXADAuM2FJRV5WFCYDYNe\n2G6uyYD+iWlc6LegrjQXdqcbTQsKkJdlQG2J8DnpPjUadMJn6xmyjXrkZRmCEi0mgw5bl1fCbHfi\nlOJBKn2uNM8ExhiuDE3h2pgdN9UXoyzPhOEpB7yc+wW/hcU5qC4SfhvpWmhUFA5UFmTjhloE/d6L\ny/JgtjnlwCcpz8+Sn1/bVy4ImeC6sbZIvidzTHrVkg7pejSHSDBpLWOCgpJUpFCaZ0JxwA0n3AzR\nb6u6KBtGvc4vKCQju23Qhy6Jkx7wEp1YXCaFibwsAxrEG/yWJaXIUdxo0oN1QaH/lw68ePQ65pcT\nWaYo3glVnBToxroiZOn1wsMvimKdcEU/gQFBwhjzCwgAUJZnwpKKPNSV5gZ9Tq8LXxx485JSzLg8\nfsuk8726pggrqgvh5RxGvS6oeBAQHtgVBVlRFzsCQu4U8A+ESoHfsTDbiJULCyMW3wUGFzUmg041\nsJSoJF6U22yszEeVyvHqdAz1Zbl+ywx6HZZWCg9+u9OjmjDKMoQ/X5sURXnSwxYQrsVw16NBDO5S\nQJYSM0rbVlRiyOLAgkIhAJbnZ8m5A6loVvm5xop8OSEI+H43p9uLK0NWuYQiErXfWwrOUjB0ur2Y\ndnlQlGPE5qYKORdn0AvHmW3UY8blweDkDPKyDH6JNLX9VRX53lf7HZIhI4OCpFzlgoiXlIrPMgY/\nrFYsLJRv9FRYUV2AHpNe9UcuyPZ/MBj1OtzZXCHfLMlUWRD6Ak0mxhiWBOTQolWYbURhduiHqV7H\noI8wb0UsASFe0QZmrZkMupA5wkiyjXq/nEAq6HQs5PGurikCY8L1onxYAkBlQZZcKqC2TbVrW7r/\nAreVCJNBJydKlInBwATU4vI85IW47poWFGDE6sDqmkKwNIwJlzFBIRUPPWE/wUFBLeWVTFkGvV9K\nPpJQqW5C5pNwD2/GWFBxXyQF2ca4A2aiwiVC68tyg3JvqZTQ04Yx9k3G2CXG2BnG2B8YY8Xxbitc\n8QshhJDUSPRJ/AaA1ZzzGwG0A3gq8UNKDk6znRFCSEQJBQXO+Z84527x5REAtYkfEiGEkHTRsszm\nLwC8puH24qILqJiRyuOlChu1TmuEEEIEESuaGWO7AVSpvPUlzvmL4jpfAuAG8Jsw29kBYAcA1NfX\nY3F5HhYUZsHm8Gg61IFOx7CluULurCTVVeRnGbCkIi9trUAIIWQ2YImWtTPGHgfwCQDbOOdRdeFr\naWnhbW1tCe2XEELmG8bYcc55UmfoSqhJKmPsXgB/B+DOaAMCIYSQzJVoncL3ARQAeIMxdoox9iMN\njokQQkiaJJRT4Jwv1epACCGEpB/1GCOEECKjoEAIIURGQYEQQoiMggIhhBAZBQVCCCGyhDuvxbVT\nxqYAXE75jjNTOYDRdB9EhqBz4UPnwofOhU8z5zz6cffjkK75FC4nu1febMEYa6NzIaBz4UPnwofO\nhQ9jLOlDQVDxESGEEBkFBUIIIbJ0BYVn0rTfTETnwofOhQ+dCx86Fz5JPxdpqWgmhBCSmaj4iBBC\niCylQYExdi9j7DJjrIMx9mQq951MjLE6xtg+xthFxth5xthnxeWljLE3GGNXxP9LxOWMMfa0eB7O\nMMbWKbb1uLj+FXGuCmn5esbYWfEzTzPGMnoKOcaYnjF2kjH2svi6gTF2VPxev2OMmcTlWeLrDvH9\nxYptPCUuv8wYe4di+ay5jhhjxYyxXYyxS+L1sWm+XheMsb8W749zjLFnGWPZ8+W6YIz9jDE2zBg7\np1iW9Osg1D7C4pyn5B8APYBOAEsAmACcBrAyVftP8nerBrBO/LsAQDuAlQC+AeBJcfmTAP5N/Ptd\nEKYuZQA2AjgqLi8F0JQndKAAAAPBSURBVCX+XyL+XSK+dwzAJvEzrwF4Z7q/d4Rz8jcA/gfAy+Lr\nnQDeJ/79IwB/Kf79SQA/Ev9+H4DfiX+vFK+RLAAN4rWjn23XEYBfAviY+LcJQPF8vC4A1AC4CiBH\ncT08MV+uCwCbAawDcE6xLOnXQah9hD3WFJ6UTQBeV7x+CsBT6f6xkvRdXwRwN4QOetXismoI/TMA\n4McAHlOsf1l8/zEAP1Ys/7G4rBrAJcVyv/Uy7R+AWgB7AGwF8LJ4oY4CMAReCwBeB7BJ/NsgrscC\nrw9pvdl0HQEoFB+ELGD5vLsuIASFXvGBZhCvi3fMp+sCwGL4B4WkXweh9hHuXyqLj6SLQtInLptT\nxGzuWgBHASzgnA8AgPh/pbhaqHMRbnmfyvJM9R0AXwDgFV+XAZjgnLvF18rjl7+z+P6kuH6s5ygT\nLQEwAuDnYlHaTxhjeZiH1wXn/DqAfwfQA2AAwu98HPPzupCk4joItY+QUhkU1Mo651TTJ8ZYPoDf\nA/gc59wSblWVZTyO5RmHMXY/gGHO+XHlYpVVeYT3Zv25gJDCXQfgh5zztQBsELLwoczZcyGWZT8I\nochnIYA8AO9UWXU+XBeRpPW7pzIo9AGoU7yuBdCfwv0nFWPMCCEg/IZz/ry4eIgxVi2+Xw1gWFwe\n6lyEW16rsjwT3QbgAcZYN4DfQihC+g6AYsaYNKyK8vjl7yy+XwTAjNjPUSbqA9DHOT8qvt4FIUjM\nx+tiO4CrnPMRzrkLwPMAbsX8vC4kqbgOQu0jpFQGhVYAy8TWBiYIlUcvpXD/SSPW9P8UwEXO+bcV\nb70EQGoh8DiEugZp+YfFVgYbAUyKWbvXAdzDGCsRU1b3QCgnHQAwxRjbKO7rw4ptZRTO+VOc81rO\n+WIIv/FezvkHAOwD8Ii4WuC5kM7RI+L6XFz+PrEVSgOAZRAq02bNdcQ5HwTQyxhrFhdtA3AB8/C6\ngFBstJExliseq3Qu5t11oZCK6yDUPkJLcUXLuyC0zOkE8KV0V/xo+L1uh5BdOwPglPjvXRDKQPcA\nuCL+XyquzwD8QDwPZwG0KLb1FwA6xH8fUSxvAXBO/Mz3EVB5mYn/AGyBr/XREgg3bweA5wBkicuz\nxdcd4vtLFJ//kvh9L0PRqmY2XUcAbgLQJl4bL0BoNTIvrwsAXwVwSTzeX0FoQTQvrgsAz0KoS3FB\nSNl/NBXXQah9hPtHPZoJIYTIqEczIYQQGQUFQgghMgoKhBBCZBQUCCGEyCgoEEIIkVFQIIQQIqOg\nQAghREZBgRBCiOz/A2V0RbuT24xXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25b92939e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state_size = 3\n",
    "action_size = 2\n",
    "global_agent = A3CAgent(state_size, action_size)\n",
    "global_agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begining Simulation...\n[(0, 20), (0, 50), (0, 6), (1, 81), (1, 71), (1, 72), (0, 8), (1, 38), (1, 52)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 56), (1, 73), (0, 3), (0, 32), (1, 77), (0, 2), (1, 65), (1, 69), (1, 100)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 42), (1, 95), (0, 25), (1, 52), (0, 36), (1, 71), (1, 33), (1, 72)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 24), (0, 26), (1, 35), (0, 22), (1, 77), (1, 87), (1, 56), (0, 36), (1, 45)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 35), (1, 87), (0, 14), (1, 94), (0, 38), (0, 18), (1, 100), (1, 51), (0, 20)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 18), (1, 88), (1, 75), (0, 31), (0, 20), (1, 72), (1, 54), (0, 46), (0, 1)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 90), (1, 76), (0, 18), (1, 100), (1, 80), (0, 87), (0, 29), (1, 99)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 99), (0, 65), (0, 30), (0, 23), (1, 25), (1, 76), (1, 58), (1, 80)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 59), (0, 10), (1, 46), (0, 16), (1, 30), (0, 16), (1, 34), (1, 72), (1, 27)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 40), (1, 90), (0, 28), (0, 34), (0, 12), (1, 39), (1, 72), (1, 60), (1, 68)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (0, 49), (0, 2), (0, 9), (1, 53), (1, 57), (1, 97), (1, 67), (1, 25)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 16), (0, 30), (1, 51), (1, 87), (1, 58), (1, 99), (0, 29), (0, 47), (0, 10)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 75), (0, 56), (1, 59), (1, 81), (1, 94), (0, 40), (1, 80)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 18), (0, 12), (1, 79), (0, 36), (1, 44), (1, 71), (0, 32), (0, 10)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 58), (0, 0), (1, 60), (1, 57), (0, 3), (1, 78), (0, 32), (1, 75), (1, 32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 30), (0, 26), (0, 8), (1, 70), (1, 78), (1, 100), (0, 29), (1, 38), (1, 40)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 13), (1, 69), (0, 42), (0, 35), (1, 36), (1, 37), (1, 49), (1, 73)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 59), (0, 30), (1, 52), (0, 0), (0, 4), (1, 94), (1, 88), (1, 24), (1, 33)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 78), (0, 54), (1, 64), (0, 2), (1, 96), (1, 92), (0, 24), (0, 14), (1, 22)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 16), (1, 88), (1, 77), (0, 34), (0, 41), (1, 91), (1, 67), (1, 50)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actor done\nMC mean:  160.6305 , Recursion Formula: 151.52748308743406\nPerformance:  90.75577917781004\n"
     ]
    }
   ],
   "source": [
    "# to evaluate the model, we let it play the game under fixed conditions\n",
    "# and compare the performance with our recursive formula\n",
    "\n",
    "game = TrafficLightsProblem()\n",
    "\n",
    "results = []\n",
    "test_lights = 10\n",
    "test_uses = 5\n",
    "print('Begining Simulation...')\n",
    "\n",
    "for i in range(2000):\n",
    "    state = game.reset(lights=test_lights, uses=test_uses)\n",
    "    done = False\n",
    "    actions =[]\n",
    "    while done is not True:\n",
    "        action = 0\n",
    "        if state[0] > 0:\n",
    "            policy = global_agent.actor.predict(np.reshape(state, [1, state_size]))[0]\n",
    "            action = np.argmax(policy)\n",
    "            if i % 100 == 0:\n",
    "                actions.append((action, state[2]))\n",
    "        state, reward, done, _ = game.step(action)\n",
    "    results.append(game.total_time)\n",
    "    if i % 100 == 0:\n",
    "        print(actions)\n",
    "\n",
    "print('actor done')\n",
    "\n",
    "result = sum(results)/len(results)\n",
    "target = estimated_time_recursion(test_lights, test_uses)\n",
    "worst_case = TIME*(test_lights - test_uses)/2\n",
    "performance = 100*(result - worst_case)/(target - worst_case)\n",
    "\n",
    "print('MC mean: ', result, ', Recursion Formula:',  target)\n",
    "print('Performance: ', performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
